


# ğŸ“Œ **Credit Card Fraud Detection**

**Machine Learning Project â€” Classification | Imbalanced Dataset | End-to-End Pipeline**

---

## ğŸš€ **Project Overview**

Credit card fraud is a major concern for banks and financial institutions. Fraudulent transactions are rare but extremely costly.
This project builds a machine learning model that **detects fraudulent transactions** using an imbalanced dataset from Kaggle.

The goal is to build a **production-ready fraud detection system** using best practices:
âœ” Exploratory Data Analysis
âœ” Handling class imbalance
âœ” Model training
âœ” Evaluation with correct metrics
âœ” Threshold tuning
âœ” Saving the final model (pickle format)



## ğŸ“Š **Dataset Information**

This dataset contains:

* **284,807 transactions**
* **492 fraud cases** (only **0.172%**) â†’ **highly imbalanced**
* Features `V1` to `V28` are PCA-transformed components (to protect sensitive customer info)
* Additional features:

  * `Time` â€” seconds elapsed between transactions
  * `Amount` â€” transaction value
* `Class` â†’ Target variable

  * `0` = Legitimate
  * `1` = Fraud



## ğŸ§  **Problem Definition**

> **Given anonymized credit card transaction data, the task is to classify whether a transaction is fraudulent or not.**

Because fraudulent transactions are extremely rare, this is an **imbalanced classification problem**.



## ğŸ› ï¸ **Project Workflow**

### **1ï¸âƒ£ Data Loading & Basic Checks**

* Shape, missing values, duplicates
* Distribution of target variable (`Class`)

### **2ï¸âƒ£ Exploratory Data Analysis**

* Class imbalance visualization
* Distribution of `Amount` and `Time`
* Correlation of features with `Class`
* Identifying most important PCA components

### **3ï¸âƒ£ Data Preprocessing**

* Scaling numerical features (StandardScaler)
* Train-test split (stratified)

### **4ï¸âƒ£ Handling Class Imbalance**

* Used **class weights** to penalize misclassification of minority class
* (Alternative techniques: SMOTE, undersampling â€” but class weights performed best)

### **5ï¸âƒ£ Model Training**

Models tried:

* Logistic Regression
* Random Forest Classifier (final chosen model)

Random Forest performed best in recall & ROC-AUC.

### **6ï¸âƒ£ Model Evaluation**

Correct metrics used:

* **Confusion Matrix**
* **Precision, Recall, F1-score**
* **ROC-AUC Score**
* **Threshold Tuning** to catch more frauds

### **7ï¸âƒ£ Saving the Final Model**

Saved using `pickle`:

```
models/
â”‚-- scaler.pkl
â”‚-- random_forest_model.pkl
```

---

## ğŸ§ª **Model Performance**

### ğŸ“Œ **Confusion Matrix (Best Threshold)**

```
[[56644     7]
 [   24    71]]
```

### ğŸ“Œ **Classification Report**

* Legit (0): **Precision 1.00 | Recall 1.00**
* Fraud (1): **Precision 0.91 | Recall 0.75**

### ğŸ“Œ **ROC-AUC Score**

```
0.973
```

Random Forest + Class Weights + Threshold tuning gives **strong recall** on fraud cases while keeping false positives very low.



## ğŸ’¾ **Files in This Repository**

```
Credit-Card-Fraud-Detection/
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ scaler.pkl                â†’ StandardScaler object
â”‚   â””â”€â”€ random_forest_model.pkl   â†’ Final trained model
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ credit_card_fraud_detection.ipynb  â†’ Full EDA + Model training code
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ§° **Technologies Used**

* **Python**
* **Pandas, NumPy**
* **Matplotlib, Seaborn**
* **Scikit-learn**
* **Imbalanced-learn (for class imbalance handling)**
* **Pickle**
* **Jupyter Notebook**

---

## ğŸ”¥ **Key Highlights of This Project**

âœ” Solved a **highly imbalanced** real-world problem
âœ” Demonstrated **EDA, visualization, and preprocessing**
âœ” Implemented class balancing using **class weights**
âœ” Built multiple ML models and selected the best one
âœ” Optimized recall using **threshold tuning**
âœ” Saved a production-ready model with scaler
âœ” Clean & professional GitHub structure

---

## ğŸ™Œ **Author**

**Ali Akbark Kanorewala**
Data Science Enthusiast | ML | Python




